# cdt/config.py
"""Configuration classes for CDT experiments - CNN-based approach."""

from dataclasses import dataclass, field, asdict
from typing import Optional, List, Dict, Any
from pathlib import Path
import json
import hashlib


@dataclass
class ModelArchitectureConfig:
    """Configuration for model architecture."""
    model_type: str = "dragonnet"  # "dragonnet" or "uplift"

    # Feature extractor type: "cnn" or "bert"
    feature_extractor_type: str = "cnn"

    # CNN architecture (used when feature_extractor_type="cnn")
    cnn_embedding_dim: int = 128  # Word embedding dimension
    cnn_kernel_sizes: List[int] = field(default_factory=lambda: [3, 4, 5, 7])
    cnn_dropout: float = 0.1
    cnn_max_length: int = 2048  # Max sequence length in tokens (words)
    cnn_min_word_freq: int = 2  # Minimum word frequency for vocabulary
    cnn_max_vocab_size: int = 50000  # Maximum vocabulary size

    # CNN embedding initialization
    cnn_use_random_embedding_init: bool = False  # If True, use random init (ignore cnn_init_embeddings_from)
    cnn_init_embeddings_from: Optional[str] = None  # e.g., "emilyalsentzer/Bio_ClinicalBERT"
    cnn_freeze_embeddings: bool = False  # Whether to freeze BERT-initialized embeddings

    # CNN filter initialization: specify each filter type separately
    # Total filters per kernel = max(explicit_count_per_kernel) + kmeans + random
    # Dict mapping kernel_size (as string in JSON) to list of concept phrases
    cnn_explicit_filter_concepts: Optional[Dict[str, List[str]]] = None
    cnn_num_kmeans_filters: int = 64  # Number of k-means derived filters per kernel size
    cnn_num_random_filters: int = 0  # Number of randomly initialized filters per kernel size
    cnn_freeze_filters: bool = False  # Whether to freeze CNN filters after initialization

    # BERT architecture (used when feature_extractor_type="bert")
    bert_model_name: str = "bert-base-uncased"  # HuggingFace model name or path
    bert_max_length: int = 512  # Max sequence length in subword tokens
    bert_projection_dim: Optional[int] = 128  # Projection dim after CLS; None = use raw hidden size
    bert_dropout: float = 0.1  # Dropout rate for projection layer
    bert_freeze_encoder: bool = False  # If True, freeze transformer (only train projection + DragonNet)
    bert_gradient_checkpointing: bool = False  # Enable gradient checkpointing for memory efficiency

    # DragonNet head dimensions
    dragonnet_representation_dim: int = 128
    dragonnet_hidden_outcome_dim: int = 64
    dragonnet_dropout: float = 0.2  # Dropout in DragonNet representation and outcome layers

    def get_num_filters_per_kernel(self) -> int:
        """
        Compute total number of filters per kernel size.

        Total = max(explicit concepts per kernel) + kmeans + random
        This ensures all kernel sizes have the same number of output channels.
        """
        max_explicit = 0
        if self.cnn_explicit_filter_concepts:
            for concepts in self.cnn_explicit_filter_concepts.values():
                max_explicit = max(max_explicit, len(concepts))
        return max_explicit + self.cnn_num_kmeans_filters + self.cnn_num_random_filters


@dataclass
class TrainingConfig:
    """Configuration for model training."""
    learning_rate: float = 1e-4
    optimizer: str = "adamw"
    lr_schedule: str = "linear"
    epochs: int = 50
    batch_size: int = 8
    alpha_propensity: float = 1.0
    beta_targreg: float = 0.1
    # Regularization options
    weight_decay: float = 0.01  # L2 regularization (AdamW decoupled weight decay)
    gradient_clip_norm: float = 1.0  # Max gradient norm (0 to disable)
    label_smoothing: float = 0.0  # Label smoothing for BCE (0 to disable)


@dataclass
class PropensityTrimmingConfig:
    """Configuration for propensity score trimming before causal inference.

    When enabled, trains a propensity-only model using k-fold cross-validation
    to generate out-of-sample propensity scores, then trims the dataset by
    removing patients with propensity scores outside the specified bounds.
    This helps enforce positivity assumption for causal inference.
    """
    enabled: bool = False  # Whether to trim by propensity before DragonNet training
    min_propensity: float = 0.1  # Remove patients with P(T=1|X) below this
    max_propensity: float = 0.9  # Remove patients with P(T=1|X) above this
    cv_folds: int = 5  # Number of CV folds for propensity model training
    propensity_epochs: int = 20  # Training epochs for propensity model
    propensity_learning_rate: float = 1e-4  # Learning rate for propensity model
    propensity_batch_size: int = 8  # Batch size for propensity model


@dataclass
class OutcomeModelConfig:
    """Configuration for standalone outcome model training.

    When enabled, trains an outcome-only model using k-fold cross-validation
    to generate out-of-sample outcome predictions. This helps assess the
    prognostic signal in the data before DragonNet training.
    Unlike propensity trimming, this does NOT trim the dataset.
    """
    enabled: bool = False  # Whether to train outcome model before DragonNet
    cv_folds: int = 5  # Number of CV folds for outcome model training
    outcome_epochs: int = 20  # Training epochs for outcome model
    outcome_learning_rate: float = 1e-4  # Learning rate for outcome model
    outcome_batch_size: int = 8  # Batch size for outcome model


@dataclass
class PlasmodeConfig:
    """Configuration for plasmode simulation."""
    generation_mode: str = "phi_linear"
    preserve_observed_treatments: bool = True
    baseline_control_outcome_rate: float = 0.20
    target_ate_prob: float = 0.10  # Target ATE on probability scale (e.g., 0.10 = 10% increase in outcome probability)
    outcome_heterogeneity_scale: float = 1.0
    ite_heterogeneity_scale: float = 1.0
    deep_nonlinear_hidden_dims: List[int] = field(default_factory=lambda: [64, 32])
    deep_nonlinear_dropout: float = 0.0
    uplift_hidden_dims: List[int] = field(default_factory=list)
    uplift_activation: str = "relu"
    uplift_dropout: float = 0.0


@dataclass
class AppliedInferenceConfig:
    """Configuration for applied inference on real data."""
    dataset_path: str = ""
    text_column: str = "clinical_text"
    outcome_column: str = "outcome_indicator"
    treatment_column: str = "treatment_indicator"
    split_column: str = "split"
    cv_folds: int = 5  # Number of CV folds (0 or 1 = fixed split)
    architecture: ModelArchitectureConfig = field(default_factory=ModelArchitectureConfig)
    training: TrainingConfig = field(default_factory=TrainingConfig)
    propensity_trimming: PropensityTrimmingConfig = field(default_factory=PropensityTrimmingConfig)
    outcome_model: OutcomeModelConfig = field(default_factory=OutcomeModelConfig)
    use_pretrained_weights: bool = False  # Not used for CNN, kept for API compatibility
    skip: bool = False  # Skip applied inference, go straight to plasmode


@dataclass
class PlasmodeExperimentConfig:
    """Configuration for plasmode sensitivity experiments."""
    enabled: bool = False
    num_repeats: int = 1
    save_datasets: bool = False
    train_fraction: float = 0.8  # Fraction of data for training (rest is eval)
    generator_architecture: ModelArchitectureConfig = field(default_factory=ModelArchitectureConfig)
    generator_training: TrainingConfig = field(default_factory=TrainingConfig)
    evaluator_architecture: ModelArchitectureConfig = field(default_factory=ModelArchitectureConfig)
    evaluator_training: TrainingConfig = field(default_factory=TrainingConfig)
    plasmode_scenarios: List[PlasmodeConfig] = field(default_factory=list)
    propensity_trimming: PropensityTrimmingConfig = field(default_factory=PropensityTrimmingConfig)
    oracle_mode: bool = False  # If True, evaluator sees generator's exact features


@dataclass
class ExperimentConfig:
    """Main configuration for CDT experiments."""
    output_dir: str = "./cdt_results"
    seed: int = 42
    device: Optional[str] = None
    num_workers: int = 1
    gpu_ids: Optional[List[int]] = None

    # Filter interpretation settings
    save_filter_interpretations: bool = False  # Save post-hoc filter interpretations after training
    filter_interpretation_top_k: int = 10  # Number of top n-grams per filter to save

    applied_inference: AppliedInferenceConfig = field(default_factory=AppliedInferenceConfig)
    plasmode_experiments: PlasmodeExperimentConfig = field(default_factory=PlasmodeExperimentConfig)

    def to_dict(self) -> Dict[str, Any]:
        """Convert config to dictionary."""
        return asdict(self)

    def to_json(self, path: str) -> None:
        """Save config to JSON file."""
        with open(path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)

    @classmethod
    def from_json(cls, path: str) -> 'ExperimentConfig':
        """Load config from JSON file."""
        with open(path, 'r') as f:
            data = json.load(f)
        return cls.from_dict(data)

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ExperimentConfig':
        """Create config from dictionary."""
        applied = AppliedInferenceConfig(
            **{k: ModelArchitectureConfig(**v) if k == 'architecture'
               else TrainingConfig(**v) if k == 'training'
               else PropensityTrimmingConfig(**v) if k == 'propensity_trimming'
               else OutcomeModelConfig(**v) if k == 'outcome_model'
               else v
               for k, v in data.get('applied_inference', {}).items()}
        )

        plasmode_data = data.get('plasmode_experiments', {})
        plasmode = PlasmodeExperimentConfig(
            enabled=plasmode_data.get('enabled', False),
            num_repeats=plasmode_data.get('num_repeats', 1),
            save_datasets=plasmode_data.get('save_datasets', False),
            train_fraction=plasmode_data.get('train_fraction', 0.8),
            generator_architecture=ModelArchitectureConfig(**plasmode_data.get('generator_architecture', {})),
            generator_training=TrainingConfig(**plasmode_data.get('generator_training', {})),
            evaluator_architecture=ModelArchitectureConfig(**plasmode_data.get('evaluator_architecture', {})),
            evaluator_training=TrainingConfig(**plasmode_data.get('evaluator_training', {})),
            plasmode_scenarios=[PlasmodeConfig(**s) for s in plasmode_data.get('plasmode_scenarios', [])],
            propensity_trimming=PropensityTrimmingConfig(**plasmode_data.get('propensity_trimming', {})),
            oracle_mode=plasmode_data.get('oracle_mode', False)
        )

        return cls(
            output_dir=data.get('output_dir', './cdt_results'),
            seed=data.get('seed', 42),
            device=data.get('device'),
            num_workers=data.get('num_workers', 1),
            gpu_ids=data.get('gpu_ids'),
            save_filter_interpretations=data.get('save_filter_interpretations', False),
            filter_interpretation_top_k=data.get('filter_interpretation_top_k', 10),
            applied_inference=applied,
            plasmode_experiments=plasmode
        )

    def get_hash(self) -> str:
        """Get hash of config for caching."""
        config_str = json.dumps(self.to_dict(), sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()[:12]

    def validate(self) -> None:
        """Validate configuration."""
        if not self.applied_inference.dataset_path:
            raise ValueError("applied_inference.dataset_path is required")

        if not Path(self.applied_inference.dataset_path).exists():
            raise ValueError(f"Dataset not found: {self.applied_inference.dataset_path}")

        if self.plasmode_experiments.enabled and not self.plasmode_experiments.plasmode_scenarios:
            raise ValueError("plasmode_experiments.plasmode_scenarios cannot be empty when enabled=True")


def create_default_config(output_path: str) -> None:
    """Create a default configuration file."""
    config = ExperimentConfig(
        output_dir="./cdt_results",
        seed=42,
        device="cuda:0",
        num_workers=1,
        gpu_ids=[0, 1],

        applied_inference=AppliedInferenceConfig(
            dataset_path="./dataset.parquet",
            cv_folds=5,
            architecture=ModelArchitectureConfig(
                cnn_init_embeddings_from="emilyalsentzer/Bio_ClinicalBERT",
                cnn_num_kmeans_filters=64,
                cnn_num_random_filters=0
            ),
            training=TrainingConfig(
                epochs=50,
                batch_size=8
            )
        ),

        plasmode_experiments=PlasmodeExperimentConfig(
            enabled=False,
            num_repeats=3,
            save_datasets=False,
            plasmode_scenarios=[
                PlasmodeConfig(
                    generation_mode="phi_linear",
                    target_ate_prob=0.10
                )
            ]
        )
    )

    config.to_json(output_path)
    print(f"Default configuration saved to: {output_path}")
