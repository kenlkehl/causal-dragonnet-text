Now I have a complete picture. Let me update the todo and provide a comprehensive analysis.

● Analysis Complete: The Root Cause is Positivity Violations, Not Dragonnet

  Your Dragonnet implementation is working correctly. The failure to learn the true ITE is caused by severe positivity violations in your synthetic data - a fundamental causal inference problem that no model can overcome.

  The Smoking Gun Evidence
  ┌──────┬───────────┬───────────┬──────────┬──────────┬──────────────┐
  │ ECOG │ N Treated │ N Control │ True ITE │ Pred ITE │   Y1 Error   │
  ├──────┼───────────┼───────────┼──────────┼──────────┼──────────────┤
  │ 0    │ 100       │ 81        │ 1.00     │ 0.94     │ Excellent    │
  ├──────┼───────────┼───────────┼──────────┼──────────┼──────────────┤
  │ 1    │ 43        │ 334       │ 0.69     │ 0.54     │ Good         │
  ├──────┼───────────┼───────────┼──────────┼──────────┼──────────────┤
  │ 2    │ 5         │ 327       │ 2.11     │ 0.05     │ Catastrophic │
  ├──────┼───────────┼───────────┼──────────┼──────────┼──────────────┤
  │ 3    │ 0         │ 110       │ 1.57     │ -0.56    │ Wrong sign!  │
  └──────┴───────────┴───────────┴──────────┴──────────┴──────────────┘
  Key observations:

  1. Where there's enough treated data (ECOG 0, 1), ITE prediction is excellent - the model learns Y1 correctly
  2. Where treated data is sparse (ECOG 2: only 5 patients), the Y1 head collapses toward Y0 - ITE is severely underestimated
  3. Where there's NO treated data (ECOG 3), the model predicts Y1 < Y0 - ITE has wrong sign!

  Why This Happens

  Your data generation creates a confounding structure that violates positivity:

  Treatment equation coefficients (from metadata):
    ecog_status_1: -2.22  (less likely to treat)
    ecog_status_2: -4.44  (much less likely)
    ecog_status_3: -6.66  (almost never treated)

  This results in treatment rates:
  - ECOG 0: 55% treated
  - ECOG 1: 11% treated
  - ECOG 2: 1.5% treated (only 5 patients!)
  - ECOG 3: 0% treated (zero patients!)

  The causal inference positivity assumption states: P(T=1|X) > 0 for all X. Your data violates this for ECOG 3 (P=0) and nearly violates it for ECOG 2 (P≈0.015).

  What Your Model Actually Learned

  The model performs correctly within the bounds of what's learnable:

  1. Y0 predictions are excellent (correlation 0.97) - plenty of control data for all ECOG levels
  2. Propensity predictions are excellent - correctly identifies who gets treated
  3. Y1 predictions are only good where treated data exists:
    - ECOG 0: True Y1=-0.55, Pred=-0.49 ✓
    - ECOG 3: True Y1=5.58, Pred=2.22 ✗ (no treated patients to learn from!)

  The Negative ITE Correlation Explained

  The correlation of -0.53 between true and predicted ITE occurs because:

  1. Patients with highest true ITE (ECOG 2) are rarely treated → Y1 poorly learned → ITE underestimated
  2. Patients with lowest true ITE (ECOG 0) are frequently treated → Y1 well learned → ITE accurate
  3. This creates a systematic bias: the more a patient should benefit, the less they're treated, so the model underestimates their benefit

  How to Fix This

  Option 1: Fix the synthetic data generation - ensure adequate overlap:
  # In generator.py, calibrate treatment equation to ensure positivity
  target_treatment_rate = 0.5
  target_min_treatment_rate_per_stratum = 0.1  # NEW parameter

  Option 2: Use a different experimental design - train on data with forced positivity, then evaluate on the realistic distribution.

  Option 3: Accept the limitation - this is a realistic clinical scenario. Doctors might avoid treating sicker patients (high ECOG) due to toxicity concerns, even if those patients benefit most. Causal inference simply cannot estimate effects for populations that never receive treatment.

  Summary

  This is not a Dragonnet bug - this is the fundamental limitation of causal inference from observational data. Your experiment actually demonstrates an important principle: you cannot learn counterfactual outcomes for subpopulations that are never exposed to the treatment.

  The fact that your model achieves excellent performance for ECOG 0/1 (where there's overlap) while failing for ECOG 2/3 (where there's no overlap) is exactly the expected behavior of any properly-specified causal model.